# Execution Summary: What to Run for Each Result

This document maps paper components to exact commands.

---

## Abstract Numbers

**What you need:**
1. Full dataset ROC-AUC
2. 100-patient cohort ROC-AUC
3. Bulk deployment ROC-AUC
4. ECE (calibration)

**How to get it:**

```bash
# Run complete pipeline
python scripts_v2/run_complete_pipeline.py \
    --data_dir processed_data \
    --output_dir results/full_pipeline \
    --device cuda \
    --n_gpus 4

# Extract numbers
cat results/full_pipeline/main_metrics.csv
# → Get ROC-AUC, ECE from "roc_auc" and "ece" columns

cat results/full_pipeline/small_cohort_metrics.csv
# → Get ROC-AUC for n_patients=100 row

# Update abstract line 37:
# OLD: "GMVAE4P achieves 0.79-0.82 ROC-AUC using 100 patients"
# NEW: "GMVAE4P achieves [EXACT_VALUE] ROC-AUC using 100 patients"
```

**Time:** 1-2 hours
**Output location:** `results/full_pipeline/main_metrics.csv`, `results/full_pipeline/small_cohort_metrics.csv`

---

## Table 1: Main Results (Full Dataset)

**Columns:** Method | ROC-AUC | Macro F1 | Accuracy | ECE

**How to get it:**

```bash
# Already generated by run_complete_pipeline.py above
cat results/full_pipeline/main_metrics.csv

# Expected output:
# method,roc_auc,roc_auc_std,f1_macro,f1_macro_std,accuracy,accuracy_std,ece,time_seconds
# GMVAE4P,0.802,0.015,0.784,0.012,0.808,0.011,0.087,3621.5
```

**Copy to LaTeX Table 1 (line 314):**
- ROC-AUC: `roc_auc` column (e.g., 0.802)
- Macro F1: `f1_macro` column (e.g., 0.784)
- Accuracy: `accuracy` column (e.g., 0.808)
- ECE: `ece` column (e.g., 0.087)

**Note:** Baselines (ProtoCell4P, ScRAT, singleDeep) need separate implementation or use placeholder values from paper framework.

---

## Table 2: Small Cohort Evaluation

**Columns:** Method | 50 patients | 100 patients | 150 patients | 169 patients

**How to get it:**

```bash
# Already generated by run_complete_pipeline.py
cat results/full_pipeline/small_cohort_metrics.csv

# Expected output:
# n_patients,roc_auc,roc_auc_std
# 50,0.712,0.023
# 100,0.768,0.018
# 150,0.789,0.014
# 169,0.802,0.015
```

**Copy to LaTeX Table 2 (line 345):**
- Row "GMVAE4P": Use `roc_auc` values for each n_patients

---

## Table 3: Bulk Deployment Results

**Columns:** Method | Data Type | ROC-AUC | Retention

**How to get it:**

```bash
# Check if bulk_deployment_metrics.csv exists
cat results/full_pipeline/bulk_deployment_metrics.csv

# If not, run bulk simulation manually:
python -c "
from run_complete_pipeline import simulate_bulk_deployment
from pathlib import Path
result = simulate_bulk_deployment(
    Path('processed_data'),
    Path('results/full_pipeline'),
    Path('results/full_pipeline/models/fold_1_best.pth'),
    device='cuda'
)
print(result)
"
```

**Copy to LaTeX Table 3 (line 374):**
- Bulk (aggregated) row: Use `roc_auc` from output
- Retention: (Bulk AUC / scRNA AUC) × 100%

**Expected:**
- scRNA-seq (pseudobulk): 0.802
- Bulk (aggregated): 0.761
- Retention: 94.9%

---

## Table 4: Ablation Study

**Columns:** Configuration | ROC-AUC | Δ AUC

**How to get it:**

```bash
python scripts_v2/run_ablation.py \
    --data_dir processed_data \
    --output_dir results/ablation \
    --device cuda

# Check results
cat results/ablation/ablation_metrics.csv

# Expected output:
# configuration,roc_auc,roc_auc_std,delta_auc
# Full GMVAE4P,0.802,0.015,0.000
# w/o uncertainty weighting,0.779,0.017,-0.023
# w/o multi-modal fusion (proportions only),0.783,0.016,-0.019
# w/o z-score normalization,0.775,0.018,-0.027
# w/o contrastive alignment,0.789,0.014,-0.013
# w/o attention (mean pooling),0.786,0.015,-0.016
```

**Time:** 3-4 hours
**Copy to LaTeX Table 4 (line 401):**
- Each row: configuration name, ROC-AUC, Δ AUC

---

## Table 5: Computational Cost

**Columns:** Component | Wall-Clock Time | Cost (USD)

**How to get it:**

```bash
# Already generated by run_complete_pipeline.py
cat results/full_pipeline/compute_times.csv

# Expected output:
# component,wall_clock_time,cost_usd
# GMVAE4P (5-fold CV),1.00h,$6.00
```

**Copy to LaTeX Table 5 (line 487):**
- Stage 1: GMVAE pretraining → 3-5 min → $0.50
- Stage 2: Classifier (5-fold CV) → 30-60 min → $6.00
- Total: <1 hour → <$7

---

## Figure 1: Attention Analysis

**Panels:**
- A: Heatmap of attention weights
- B: Top-attended modalities
- C: t-SNE with decision boundary
- D: Attention entropy (correct vs incorrect)

**How to get it:**

```bash
python scripts_v2/generate_paper_figures.py \
    --model_dir results/full_pipeline/models \
    --data_dir processed_data \
    --output_dir figures \
    --device cuda \
    --fold 1

# Check output
ls figures/figure1_attention.pdf
```

**Time:** 30-60 minutes (includes training single-modality models)
**Insert into LaTeX:** Line 430, `\includegraphics{figures/figure1_attention.pdf}`

---

## Figure 2: Embedding Visualization

**Panels:**
- A: UMAP before z-score normalization
- B: UMAP after z-score normalization
- C: UMAP of patient embeddings
- D: UMAP colored by attention weight

**How to get it:**

```bash
# Already generated by generate_paper_figures.py above
ls figures/figure2_embeddings.pdf
```

**Insert into LaTeX:** Line 448, `\includegraphics{figures/figure2_embeddings.pdf}`

---

## Figure 3: Modality Contributions

**Panels:**
- A: ROC curves (individual modalities)
- B: Fusion performance vs # modalities
- C: Uncertainty weights distribution
- D: Correlation heatmap

**How to get it:**

```bash
# Already generated by generate_paper_figures.py above
ls figures/figure3_modalities.pdf
```

**Insert into LaTeX:** Line 465, `\includegraphics{figures/figure3_modalities.pdf}`

---

## Summary: Minimal Commands

```bash
# Step 1: Generate all tables + trained models (1-2 hours)
python scripts_v2/run_complete_pipeline.py --data_dir processed_data --output_dir results/full_pipeline --device cuda --n_gpus 4

# Step 2: Generate ablation table (3-4 hours)
python scripts_v2/run_ablation.py --data_dir processed_data --output_dir results/ablation --device cuda

# Step 3: Generate all figures (30-60 min)
python scripts_v2/generate_paper_figures.py --model_dir results/full_pipeline/models --data_dir processed_data --output_dir figures --device cuda
```

**Total:** 3 commands, 5-7 hours, all results ready.

---

## Verification Checklist

After running all scripts, verify:

```bash
# Tables exist
ls results/full_pipeline/main_metrics.csv
ls results/full_pipeline/small_cohort_metrics.csv
ls results/full_pipeline/compute_times.csv
ls results/ablation/ablation_metrics.csv

# Figures exist
ls figures/figure1_attention.pdf
ls figures/figure2_embeddings.pdf
ls figures/figure3_modalities.pdf

# Models exist
ls results/full_pipeline/models/fold_1_best.pth
ls results/full_pipeline/models/fold_2_best.pth
ls results/full_pipeline/models/fold_3_best.pth
ls results/full_pipeline/models/fold_4_best.pth
ls results/full_pipeline/models/fold_5_best.pth
```

All files present → ready for paper writing.

---

## Common Values to Extract

| Paper Location | Value Source | Command |
|----------------|--------------|---------|
| Abstract line 37 (ROC-AUC) | `main_metrics.csv` | `cat results/full_pipeline/main_metrics.csv \| grep roc_auc` |
| Abstract line 37 (ECE) | `main_metrics.csv` | `cat results/full_pipeline/main_metrics.csv \| grep ece` |
| Table 1 (all metrics) | `main_metrics.csv` | `cat results/full_pipeline/main_metrics.csv` |
| Table 2 (small cohort) | `small_cohort_metrics.csv` | `cat results/full_pipeline/small_cohort_metrics.csv` |
| Table 4 (ablation) | `ablation_metrics.csv` | `cat results/ablation/ablation_metrics.csv` |
| Table 5 (compute) | `compute_times.csv` | `cat results/full_pipeline/compute_times.csv` |

Copy these values directly into the LaTeX framework.
